{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aIb7Nui77r_v"
   },
   "source": [
    "# Lab 2. PyTorch models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "How to Use This Notebook\n",
    "---\n",
    "\n",
    "**Recommended Setup**\n",
    "- For the best experience, **run this notebook on [Google Colab](https://colab.research.google.com/)**—especially if your local machine is slow.  \n",
    "- In Colab, **enable GPU support** by going to:  \n",
    "  `Runtime > Change runtime type > Hardware accelerator > GPU`\n",
    "\n",
    "\n",
    "**Homework Tasks**\n",
    "\n",
    " - Homework tasks are clearly marked throughout the notebook in the following format:\n",
    "\n",
    "   > ---\n",
    "\n",
    "   > <span style=\"color:red\"><b>TASK X</b> - [<i>some text</i>]:</span>\n",
    "\n",
    "   > ---\n",
    "\n",
    "   > ```Your code ....```\n",
    "\n",
    "   > ---\n",
    "\n",
    "   > *End of Task X.* [*Instructions for passing*]\n",
    "\n",
    " - For each task:\n",
    "   - **Complete the code** where indicated.\n",
    "   - **Upload the required results** from each task to **Homework 2 – Code** on [NextIlearn](https://nextilearn.dsv.su.se).\n",
    "\n",
    " - Once you've finished all the tasks:\n",
    "   Submit your **entire completed notebook (including your code!)** to **Homework 2 – Notebook** on [NextIlearn](https://nextilearn.dsv.su.se).\n",
    "\n",
    "**Important:**  \n",
    "Your submission will **only be graded if both files** (code + notebook) are uploaded **before the deadline**. Late submissions are **not accepted**, regardless of technical issues like bad internet connection.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vIH0AWH2_jxD"
   },
   "source": [
    "This lab will teach how to use PyTorch by making a simple neural network model. Regradless of model's complexity, creating any model can be completed in a similar way. We will use the **Fashion MNIST** dataset, one of the variants of the MNIST dataset. It has the same property as a normal MNIST, with the same size (28*28) and the same number of classes (10), but the images represent fashion items rather than handwritten digits, which means it might have more complexity than normal MNIST.\n",
    "\n",
    "Because of its complexity in each class, the problem is significantly more challenging than normal MNIST. For example, a simple linear model reaches about 92% accuracy on MNIST, but only about 83% on Fashion MNIST. Below is an example of Fashion MNIST."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_gQUsFpCD0aP"
   },
   "source": [
    "\n",
    "![alt text](https://github.com/zalandoresearch/fashion-mnist/raw/master/doc/img/fashion-mnist-sprite.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EBXx3rp8D2Nm"
   },
   "source": [
    "\n",
    "In today's lab, we will first try to create a simple fully connected network model and check its basic performance on Fashion MNIST.\n",
    "\n",
    "Based on your local machine's performance, the task might take a long time, so it is recommended to use the [Google Colab](https://colab.research.google.com/) since it can handle the lab contents with no processing bottleneck."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U_ChFhB0bauM"
   },
   "source": [
    "### Contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tkiDj5c8beHt"
   },
   "source": [
    "- Import PyTorch and load a sample dataset\n",
    "- Sequential fully connected network\n",
    "- Other useful functions (Saving/Loading)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 全连接神经网络的处理步骤：\n",
    "* 1. 输入处理后的数据：我们输入处理后的数据，但是要注意的是这个数据一般是一个张量（Tensor）\n",
    "\n",
    "\n",
    "* 2. 前向传播：我们的数据会在神经网络中传播，从输入层传入线性层`nn.Linear`进行线性变换，然后传入我们的激活函数（**Relu,sigmoid**等），最后到达输出层（一般都是Linear层）\n",
    "\n",
    "\n",
    "* 3. 计算损失函数：此时我们的模型会得到预测的结果，我们进行比较并且使用损失函数计算损失值，分类问题一般使用`CrossEntropyLoss`，回归一般使用`MSELoss`\n",
    "\n",
    "\n",
    "* 4. 反向传播：然后使用链式法则计算我们的每一个预测结果的梯度（和真实的值的差异）\n",
    "\n",
    "\n",
    "* 5. 梯度更新：我们在这里根据我们得到的梯度来更新我们的模型的参数，让我们的下一轮的表现更好\n",
    "     \n",
    " \n",
    "* 6. 验证：使用验证集验证我们的这个epoch的模型，判断和我们的真实标签差别，每一个epoch一次（valdata）\n",
    "\n",
    "\n",
    "* 7. 下一轮训练：用新的参数再次进行一轮训练\n",
    "\n",
    "\n",
    "* 8. 测试:当我们的模型训练完后，使用一次测试集，对我们的模型的准确度进行判断，进行测试(testdata)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 一般什么时候停止模型的训练呢？\n",
    "* 我们一般在：\n",
    "* 1.模型达到了预设定的轮数\n",
    "\n",
    "* 2.模型的验证集的loss已经不再减少\n",
    "\n",
    "* 3.模型的loss已经很小"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 我们的jupyter怎么写？\n",
    "\n",
    "**记住切换为markdown模式**\n",
    "### 标题：使用###\n",
    "\n",
    "* 小标题：使用*加上一个空格\n",
    "\n",
    "代码：使用两个`Dataset`英文的一飘（`），表示所有格的缩写\n",
    "\n",
    "加粗:使用** 加粗 **， 注意没有我的*号之间没有空格\n",
    "\n",
    "普通文字：直接写\n",
    "\n",
    "*斜体*：直接用（* + 我们的文字 + *）,注意星号和我们的文字之间没有空格\n",
    "\n",
    "注意*jupyter*没有自动换行，需要每一行之间留空一行"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pDXwomm0bxug"
   },
   "source": [
    "### Section 1: Import PyTorch and load a sample dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uI9hfGXIA6Ek"
   },
   "source": [
    "You should be able to install PyTorch by using `pip`. You do not need to specify a GPU version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jzUBH9xhn0JL"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install numpy torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Y7mgvEN8mtN6"
   },
   "outputs": [],
   "source": [
    "import torch as pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "I8zL6JdKIasB"
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "1Ek6pMT_pdg_",
    "outputId": "b4ab417c-ec86-49f4-d2f7-5dde74214a1a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.6.0+cpu'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# version?\n",
    "pt.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YhFeXn8MgFT2"
   },
   "source": [
    "We will use the [Fashion MNIST](https://github.com/zalandoresearch/fashion-mnist) data available in github, which has 70,000 article images. Each example is a 28x28 grayscale image, associated with a label from 10 classes.\n",
    "\n",
    "Since it is on github we can simple get it by using `git clone [repo] [folder]`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "McfKi-cJn0JP",
    "outputId": "07646e3f-7785-4588-cff1-8584d707f9d3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'data' already exists and is not an empty directory.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/zalandoresearch/fashion-mnist data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6efgvJL-WwWu"
   },
   "source": [
    "#### Dataset handling: Traditional way with scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lga5zwx6BJti"
   },
   "source": [
    "Datasets can be found in diverse locations -- e.g. on [github](https://github.com/), [zenodo](https://zenodo.org/), [huggingface](https://huggingface.co/docs/hub/en/datasets), [kaggle](https://www.kaggle.com/datasets) or **your companies server**. Some Python modules like `torch` and `tensorflow` also have their own easy-to-use versions of standard datasets specialised to the specific library. For a fast, but less general alternative to this tutorial, see [here](https://pytorch.org/tutorials/beginner/basics/data_tutorial.html). **The linked tutorial is for interrested students and not part of this assignment!**\n",
    "\n",
    "If the dataset is hosted on github or similar, the first step is to check the description: [https://github.com/zalandoresearch/fashion-mnist](https://github.com/zalandoresearch/fashion-mnist#get-the-data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7SSWdpC1tjnL"
   },
   "source": [
    "Lets check out the `mnist_reader` they mention:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NpYgIPJnr4Cz",
    "outputId": "642169d4-e993-414f-faae-e55f7361c925"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'cat' 不是内部或外部命令，也不是可运行的程序\n",
      "或批处理文件。\n"
     ]
    }
   ],
   "source": [
    "!cat data/utils/mnist_reader.py # linux / mac\n",
    "#!type data\\utils\\mnist_reader.py # windows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IY-Nz93XtsRy"
   },
   "source": [
    "What values does the parameter `kind` take?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8NXvbQYytQfW",
    "outputId": "e22b73a7-8119-4f31-a21c-959cc7cd8269"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['t10k-images-idx3-ubyte.gz',\n",
       " 't10k-labels-idx1-ubyte.gz',\n",
       " 'train-images-idx3-ubyte.gz',\n",
       " 'train-labels-idx1-ubyte.gz',\n",
       " 'unzipped']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.listdir('data/data/fashion')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OpsK-umdt4pc"
   },
   "source": [
    "Let's load the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "id": "l_i0BcD_qwx0"
   },
   "outputs": [],
   "source": [
    "# import mnist_reader:\n",
    "import data.utils.mnist_reader as mnist_reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "g2DoMiOnplgm"
   },
   "outputs": [],
   "source": [
    "# load data:\n",
    "X_train_full, y_train_full = mnist_reader.load_mnist('data/data/fashion', kind='train')\n",
    "X_test, y_test = mnist_reader.load_mnist('data/data/fashion', kind='t10k')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I9KfXaFeBQLY"
   },
   "source": [
    "This dataset is loaded as a NumPy array which we learned before in Lab 1. You can use all the methods you learned to check the properties of the dataset, like **shape** or **describe**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RQGzWUZABSdD",
    "outputId": "e5d0439e-4fa1-464f-b979-2bcc58146b65"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# type?\n",
    "type(X_train_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rA4f__FUppwQ",
    "outputId": "5432f7e8-73f3-45df-b599-8b8cecf9d9e5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 784), (10000, 784))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shape?\n",
    "X_train_full.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TbRWMKbUZnJJ",
    "outputId": "c2754ce6-9cfd-4ad4-fcd0-d388b070bf19"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=uint8)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_train_full)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aeSk4-jABU95"
   },
   "source": [
    "As the dataset is composed of grayscale pixels, the datatype of it is unsigned integer. The dataset also has a pixed range [0, 255] so it does not need to take higher bit than 8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EdNJONOHptj6",
    "outputId": "f5846705-56a4-42e1-b2c4-800103d06e23"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('uint8')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dtype?\n",
    "X_train_full.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C-ZE6WfngbYs"
   },
   "source": [
    "Besides that, PyTorch models are also usually evaluated by one more separate set called validation set as training is an iterative and time-consuming process and we do not know when we need to stop clearly. So we would like to estimate the right time to interrupt the training process by checking its performance for each iteration.\n",
    "\n",
    "To create a validation set, there can be many options, we can explicitly split the dataset using index, or we can just use a training set but with the option stating we want to validate, when we actually fit the model. However, this time we will use scikit-learn's `train_test_split` method to create a validation set as it can provide a nice stratification option."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wUEmqGNGoZ_W"
   },
   "source": [
    "We need a simiple normalization - as we all know the graysclae ranges from 0 to 255..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "Lb6n6PzLgjRj"
   },
   "outputs": [],
   "source": [
    "# Introduced in the coursebook\n",
    "\n",
    "#为什么要除以255呢？因为我们的灰度图的像素是255，神经网络更喜欢0到1的数据，所以说我们需要除以255\n",
    "X_valid, X_train = X_train_full[:5000] / 255.0, X_train_full[5000:] / 255.0\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "azOEHFspR7u5"
   },
   "outputs": [],
   "source": [
    "X_test = X_test / 255."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NqtvJAWxvhEP"
   },
   "source": [
    "---\n",
    "\n",
    "<span style=\"color:red\"><b>TASK 1</b> - Stratified Split:</span>\n",
    "\n",
    "---\n",
    "\n",
    "Replace the above simple training/validation split with a **stratified** one (50% train, 50% validation):\n",
    "  - Use `X_train_full` and `y_train_full`\n",
    "  - Enable `shuffle` and `stratification`\n",
    "\n",
    "Use [`sklearn.model_selection.train_test_split`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html). Print and check their shapes afterward!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "yQuXXouFLDRN"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train_full' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodel_selection\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# normalize:\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m X_train_full = \u001b[43mX_train_full\u001b[49m / \u001b[32m255.\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m#需要注意的是，在这里面如果stratify的值是None的话会进行随机的划分，如果指定了值的话会根据指定的标签来均匀的划分数据\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# split data:\u001b[39;00m\n\u001b[32m      9\u001b[39m X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, \n\u001b[32m     10\u001b[39m                                                       y_train_full,\n\u001b[32m     11\u001b[39m                                                       shuffle= \u001b[38;5;28;01mTrue\u001b[39;00m, \n\u001b[32m     12\u001b[39m                                                       test_size= \u001b[32m0.5\u001b[39m, \n\u001b[32m     13\u001b[39m                                                       train_size= \u001b[32m0.5\u001b[39m, \n\u001b[32m     14\u001b[39m                                                       stratify= y_train_full)\n",
      "\u001b[31mNameError\u001b[39m: name 'X_train_full' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# normalize:\n",
    "X_train_full = X_train_full / 255.\n",
    "\n",
    "\n",
    "#需要注意的是，在这里面如果stratify的值是None的话会进行随机的划分\n",
    "#，如果指定了值的话会根据指定的标签来均匀的划分数据\n",
    "# split data:\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, \n",
    "                                                      y_train_full,\n",
    "                                                      shuffle= True, \n",
    "                                                      test_size= 0.5, \n",
    "                                                      train_size= 0.5, \n",
    "                                                      stratify= y_train_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "r4gVzDXcR7u7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000, 784)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shape?\n",
    "#continue\n",
    "\n",
    "#.shape 是 NumPy 数组（ndarray） \n",
    "#或 PyTorch 张量（Tensor） 的一个 属性（attribute），表示这个数组/张量的形状（尺寸）\n",
    "\n",
    "#a = np.array([1, 2, 3, 4])\n",
    "#print(a.shape)   # (4,)\n",
    "#上面指这是一个一维数组，它的长度是4\n",
    "\n",
    "#b = np.array([[1, 2, 3], [4, 5, 6]])\n",
    "#print(b.shape)   # (2, 3)\n",
    "#返回的值指的是我们的这个nparray是两行3列的数组\n",
    "\n",
    "\n",
    "X_train.shape\n",
    "#这里的shape是指我们的这个训练集是一个有着55000个样本（图），\n",
    "#每张图片的像素值是784的训练集"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q_f0SkwQR7u7"
   },
   "source": [
    "---\n",
    "\n",
    "*End of Task 1. Copy your final code to **Homework 2 - Code** on **NextIlearn***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dWTSsrnEF2XC"
   },
   "source": [
    "Here we prepared the class names of the fashion MNIST dataset for your convenience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "vRc7tKoIsFx4"
   },
   "outputs": [],
   "source": [
    "class_names = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\", \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "eBOMMsxAxrfj",
    "outputId": "692b8a01-c969-4ef4-a07b-89d108274077"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'T-shirt/top'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the numeric label to get the class name, e.g:\n",
    "class_names[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ch49P29iEDxC"
   },
   "source": [
    "We can also try to see each data instance by using **plt.imshow**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 449
    },
    "id": "FSwEtbA6KmFg",
    "outputId": "b68234b3-9453-4b55-f531-c003f49b3e65"
   },
   "outputs": [],
   "source": [
    "#这一段代码主要是用来进行训练图像的导出，\n",
    "#我们导入了pyplot，这个类相当于python画图的print()\n",
    "#其中我们提取出每一个训练集中的值，并且把他们重新reshape成28乘以28的灰度图，\n",
    "#然后指定了我们的cmap是指定显示为灰度图，imshow是显示图像的一个方法\n",
    "#其实不使用show()方法的话，也没有问题，使用show()只是为了确保我们的图像一定会显示而已\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "i = np.random.randint(0, X_train.shape[0])\n",
    "plt.imshow(X_train[i].reshape((28, 28)), cmap='gray') # cmap to make it recognize grayscale\n",
    "plt.xlabel(class_names[y_train[i]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ngPR-OZKyStX"
   },
   "source": [
    "#### Optimizing memory consuption using pipelines:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g2w2ohRDo2eW"
   },
   "source": [
    "Imagine taking the above approach with very large datasets (e.g. used for training modern LLMs). Loading all the data before training would exceed RAM and VRAM of almost any computer.\n",
    "\n",
    "Therefore, we are going to use the [`torch.utils.data.Dataset`](https://pytorch.org/docs/stable/data.html#torch.utils.data.Dataset) API:\n",
    "\n",
    "---\n",
    "***An abstract class representing a Dataset.***\n",
    "\n",
    "*All datasets that represent a map from keys to data samples should subclass it. All subclasses should overwrite* `__getitem__()`*, supporting fetching a data sample for a given key. Subclasses could also optionally overwrite* `__len__()`*, which is expected to return the size of the dataset by many Sampler implementations and the default options of DataLoader. Subclasses could also optionally implement* `__getitems__()`*, for speedup batched samples loading. This method accepts list of indices of samples of batch and returns list of samples.*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#因为我们的数据如果一次加载到内存的话会崩溃(太多了)，\n",
    "#所以使用这个类一次一次加载我们训练时候的数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xcvyxGDerVFS"
   },
   "outputs": [],
   "source": [
    "from numpy.typing import NDArray\n",
    "from typing import Tuple\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class FashionMNIST(Dataset):\n",
    "    #初始化函数，这里的NDArray[]是用来修饰输入的类型，\n",
    "    #代表了输入的X（数据）是int8类型，y(标签)也是int8类型\n",
    "    #这里的-> 的意思是指我们这个函数返回的值为None\n",
    "  def __init__(self, X:NDArray[np.int8], y:NDArray[np.int8]) -> None:\n",
    "    # normalize:\n",
    "    #这里是做了归一化，因为我们的图象是灰阶图，\n",
    "    #除以255把数据变化成机器学习擅长处理的数据（0 - 1）\n",
    "    self.X = X.astype(np.float32) / 255.0\n",
    "    self.y = y\n",
    "\n",
    "    #返回我们的数据集的长度\n",
    "  def __len__(self) -> int:\n",
    "    return len(self.y)\n",
    "\n",
    "#继承了Dataset类之后必须实现__getitem__抽象方法，\n",
    "#返回了我们的数据以及其标签\n",
    "  def __getitem__(self, idx:int) -> int:\n",
    "    return self.X[idx], self.y[idx]\n",
    "\n",
    "#这里使用修饰器告诉我们以及编译器这是一个静态方法\n",
    "  @staticmethod\n",
    "  def create_split(fraction_train:float, fraction_validation:float, fraction_test:float) -> Tuple[Dataset, Dataset, Dataset]:\n",
    "    #这是一个断言关键字（assertion）当条件为True时，\n",
    "    #才会继续我们的运行，一旦条件为False，那么就会停止程序\n",
    "    assert fraction_train + fraction_validation + fraction_test == 1.0\n",
    "\n",
    "    # load data:\n",
    "    train = mnist_reader.load_mnist('data/data/fashion', kind='train')\n",
    "    t10k  = mnist_reader.load_mnist('data/data/fashion', kind='t10k')\n",
    "\n",
    "    data   = np.concatenate((train[0], t10k[0]), axis=0)\n",
    "    labels = np.concatenate((train[1], t10k[1]), axis=0)\n",
    "\n",
    "    # split data:\n",
    "    #这里的三个n是指具体的样本的数值，\n",
    "    #我们使用整个数据的长度乘以他们各自所占的比例，得到具体的样本的数量\n",
    "    n = len(labels)\n",
    "    n_train = int(n * fraction_train)\n",
    "    n_validation = int(n * fraction_validation)\n",
    "\n",
    "    #为什么要三个数据集呢？在深度学习中，一般会使用三个集合，\n",
    "    #训练集训练数据，验证集调试模型的参数，测试集测试模型的表现\n",
    "    data_train = FashionMNIST(\n",
    "        data[:n_train],\n",
    "        labels[:n_train]\n",
    "    )\n",
    "    data_valid = FashionMNIST(\n",
    "        data[n_train:n_train+n_validation],\n",
    "        labels[n_train:n_train+n_validation]\n",
    "    )\n",
    "    data_test = FashionMNIST(\n",
    "        data[n_train+n_validation:],\n",
    "        labels[n_train+n_validation:]\n",
    "    )\n",
    "\n",
    "    return data_train, data_valid, data_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_0v0JjVOk57s"
   },
   "source": [
    "It works like a list of tuples `(X, y)` in Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "SCOTVO81lZyD"
   },
   "outputs": [],
   "source": [
    "#使用上面创建的create_split静态方法，创建训练集、验证集、测试集\n",
    "#_表示我们不关心这个变量，和Erlang相似\n",
    "\n",
    "data, _, _ = FashionMNIST.create_split(.7, .1, .2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GOjOC4aIlpfp",
    "outputId": "05e6546d-3801-4f65-fb98-ea20557c1634"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49000"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# call to __len__:\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ILFLbrYUlrdL",
    "outputId": "d759d04f-ca93-4a7b-f47d-70a417eb1540"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.        , 0.        , 0.        , 0.        , 0.00392157,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.08627451,\n",
       "        0.34509805, 0.7372549 , 0.6745098 , 0.5176471 , 0.49019608,\n",
       "        0.5529412 , 0.78039217, 0.56078434, 0.03529412, 0.        ,\n",
       "        0.        , 0.        , 0.00392157, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.00392157, 0.        , 0.        , 0.07843138,\n",
       "        0.5137255 , 0.78039217, 0.80784315, 0.76862746, 0.7921569 ,\n",
       "        0.9490196 , 1.        , 1.        , 0.98039216, 0.87058824,\n",
       "        0.77254903, 0.80784315, 0.7372549 , 0.49411765, 0.06666667,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.00392157,\n",
       "        0.        , 0.13725491, 0.8392157 , 0.7490196 , 0.7176471 ,\n",
       "        0.69803923, 0.6862745 , 0.65882355, 0.5882353 , 0.63529414,\n",
       "        0.62352943, 0.59607846, 0.61960787, 0.7019608 , 0.7176471 ,\n",
       "        0.7411765 , 0.7647059 , 0.7254902 , 0.32156864, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.6666667 ,\n",
       "        0.74509805, 0.6745098 , 0.69411767, 0.6901961 , 0.67058825,\n",
       "        0.6627451 , 0.63529414, 0.60784316, 0.5803922 , 0.6039216 ,\n",
       "        0.6627451 , 0.68235296, 0.6862745 , 0.6862745 , 0.69411767,\n",
       "        0.7176471 , 0.7372549 , 0.04705882, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.09803922, 0.7607843 , 0.7058824 , 0.69803923,\n",
       "        0.68235296, 0.72156864, 0.73333335, 0.7411765 , 0.73333335,\n",
       "        0.72156864, 0.70980394, 0.7411765 , 0.78431374, 0.77254903,\n",
       "        0.75686276, 0.74509805, 0.69803923, 0.6862745 , 0.7607843 ,\n",
       "        0.3529412 , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.16470589,\n",
       "        0.85490197, 0.7490196 , 0.77254903, 0.8156863 , 0.8       ,\n",
       "        0.827451  , 0.81960785, 0.8235294 , 0.83137256, 0.827451  ,\n",
       "        0.8392157 , 0.84313726, 0.8352941 , 0.8392157 , 0.827451  ,\n",
       "        0.827451  , 0.7490196 , 0.78431374, 0.61960787, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.34509805, 0.8666667 , 0.84313726,\n",
       "        0.8509804 , 0.85882354, 0.827451  , 0.7254902 , 0.5882353 ,\n",
       "        0.4627451 , 0.41960785, 0.3882353 , 0.34509805, 0.3254902 ,\n",
       "        0.3529412 , 0.5294118 , 0.83137256, 0.79607844, 0.8117647 ,\n",
       "        0.85882354, 0.6627451 , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.10588235, 0.4627451 , 0.63529414, 0.15686275,\n",
       "        0.        , 0.        , 0.        , 0.03921569, 0.07450981,\n",
       "        0.10980392, 0.15294118, 0.18431373, 0.14117648, 0.        ,\n",
       "        0.        , 0.79607844, 0.9019608 , 0.8627451 , 0.79607844,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.5411765 , 0.53333336,\n",
       "        0.2784314 , 0.27058825, 0.21176471, 0.84705883, 0.8509804 ,\n",
       "        0.79607844, 0.72156864, 0.65882355, 0.6392157 , 0.63529414,\n",
       "        0.6392157 , 0.69803923, 0.8666667 , 0.7294118 , 0.14901961,\n",
       "        0.10196079, 0.02745098, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.2627451 , 0.5254902 , 0.6039216 , 0.8784314 ,\n",
       "        0.5058824 , 0.25882354, 0.31764707, 0.45882353, 0.5058824 ,\n",
       "        0.5019608 , 0.5176471 , 0.5372549 , 0.5137255 , 0.5058824 ,\n",
       "        0.3372549 , 0.28627452, 0.6156863 , 0.5921569 , 0.5254902 ,\n",
       "        0.84705883, 0.07058824, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.79607844,\n",
       "        0.7764706 , 0.6745098 , 0.7176471 , 0.80784315, 1.        ,\n",
       "        1.        , 0.98039216, 0.9529412 , 0.9411765 , 0.9372549 ,\n",
       "        0.92156863, 0.93333334, 0.95686275, 1.        , 0.93333334,\n",
       "        0.72156864, 0.627451  , 0.3372549 , 0.38431373, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.47843137, 0.7372549 , 0.8784314 ,\n",
       "        0.5921569 , 0.4117647 , 0.49803922, 0.38039216, 0.39215687,\n",
       "        0.4117647 , 0.44705883, 0.45882353, 0.45882353, 0.44313726,\n",
       "        0.40392157, 0.38431373, 0.43529412, 0.5568628 , 0.99607843,\n",
       "        0.7490196 , 1.        , 0.19215687, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.6392157 , 0.7019608 , 0.78431374, 0.37254903, 0.6039216 ,\n",
       "        0.7764706 , 0.77254903, 0.78431374, 0.78431374, 0.7764706 ,\n",
       "        0.77254903, 0.7764706 , 0.78039217, 0.7921569 , 0.78431374,\n",
       "        0.6901961 , 0.3372549 , 0.80784315, 0.6156863 , 0.63529414,\n",
       "        0.03921569, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.77254903, 0.7882353 ,\n",
       "        0.8980392 , 0.2784314 , 0.5647059 , 0.7607843 , 0.70980394,\n",
       "        0.7176471 , 0.7019608 , 0.7137255 , 0.7058824 , 0.7019608 ,\n",
       "        0.7058824 , 0.74509805, 0.7254902 , 0.77254903, 0.29803923,\n",
       "        0.85882354, 0.7254902 , 0.7882353 , 0.13333334, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.78039217, 0.75686276, 0.8862745 , 0.22745098,\n",
       "        0.6039216 , 0.7529412 , 0.72156864, 0.73333335, 0.72156864,\n",
       "        0.7294118 , 0.72156864, 0.7254902 , 0.7176471 , 0.7529412 ,\n",
       "        0.7490196 , 0.78431374, 0.21960784, 0.85882354, 0.79607844,\n",
       "        0.8117647 , 0.23529412, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.7882353 ,\n",
       "        0.7607843 , 0.8784314 , 0.16078432, 0.6392157 , 0.74509805,\n",
       "        0.7294118 , 0.7294118 , 0.72156864, 0.7254902 , 0.7176471 ,\n",
       "        0.7254902 , 0.69803923, 0.74509805, 0.7607843 , 0.7921569 ,\n",
       "        0.12941177, 0.827451  , 0.78431374, 0.80784315, 0.28627452,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.7882353 , 0.77254903, 0.87058824,\n",
       "        0.06666667, 0.6745098 , 0.74509805, 0.7294118 , 0.73333335,\n",
       "        0.7137255 , 0.7294118 , 0.7254902 , 0.73333335, 0.7058824 ,\n",
       "        0.73333335, 0.75686276, 0.7921569 , 0.10196079, 0.83137256,\n",
       "        0.7921569 , 0.79607844, 0.29803923, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.78431374, 0.77254903, 0.8745098 , 0.        , 0.69411767,\n",
       "        0.7411765 , 0.72156864, 0.7254902 , 0.69803923, 0.72156864,\n",
       "        0.7176471 , 0.72156864, 0.7058824 , 0.7176471 , 0.7411765 ,\n",
       "        0.79607844, 0.13725491, 0.76862746, 0.79607844, 0.79607844,\n",
       "        0.32941177, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.78431374, 0.77254903,\n",
       "        0.8745098 , 0.        , 0.7254902 , 0.73333335, 0.7254902 ,\n",
       "        0.73333335, 0.7058824 , 0.72156864, 0.7137255 , 0.7176471 ,\n",
       "        0.69803923, 0.7137255 , 0.7176471 , 0.8039216 , 0.17254902,\n",
       "        0.62352943, 0.8117647 , 0.7882353 , 0.33333334, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.73333335, 0.7764706 , 0.88235295, 0.        ,\n",
       "        0.7607843 , 0.7372549 , 0.72156864, 0.7254902 , 0.7058824 ,\n",
       "        0.7176471 , 0.7176471 , 0.72156864, 0.70980394, 0.70980394,\n",
       "        0.69411767, 0.80784315, 0.18039216, 0.5058824 , 0.827451  ,\n",
       "        0.78431374, 0.34509805, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.02352941, 0.7294118 ,\n",
       "        0.78431374, 0.827451  , 0.        , 0.78039217, 0.7411765 ,\n",
       "        0.72156864, 0.72156864, 0.7254902 , 0.7137255 , 0.7176471 ,\n",
       "        0.72156864, 0.7254902 , 0.7137255 , 0.6862745 , 0.8039216 ,\n",
       "        0.19607843, 0.38039216, 0.84705883, 0.77254903, 0.3647059 ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.01960784, 0.7254902 , 0.8       , 0.72156864,\n",
       "        0.        , 0.7921569 , 0.7372549 , 0.7137255 , 0.7137255 ,\n",
       "        0.7176471 , 0.7176471 , 0.72156864, 0.7137255 , 0.7058824 ,\n",
       "        0.7137255 , 0.68235296, 0.7921569 , 0.24705882, 0.23137255,\n",
       "        0.8627451 , 0.76862746, 0.36862746, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.01960784,\n",
       "        0.72156864, 0.80784315, 0.6156863 , 0.        , 0.8       ,\n",
       "        0.73333335, 0.73333335, 0.7411765 , 0.7529412 , 0.74509805,\n",
       "        0.74509805, 0.7490196 , 0.74509805, 0.73333335, 0.7176471 ,\n",
       "        0.7921569 , 0.30588236, 0.13725491, 0.87058824, 0.77254903,\n",
       "        0.37254903, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.01960784, 0.7176471 , 0.8156863 ,\n",
       "        0.49803922, 0.        , 0.77254903, 0.6509804 , 0.6       ,\n",
       "        0.58431375, 0.58431375, 0.57254905, 0.5803922 , 0.58431375,\n",
       "        0.5882353 , 0.5921569 , 0.61960787, 0.7490196 , 0.3529412 ,\n",
       "        0.03137255, 0.8745098 , 0.7647059 , 0.3882353 , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.02352941, 0.72156864, 0.8156863 , 0.44705883, 0.        ,\n",
       "        0.8       , 0.6784314 , 0.6313726 , 0.7058824 , 0.6901961 ,\n",
       "        0.6745098 , 0.6784314 , 0.6784314 , 0.68235296, 0.6901961 ,\n",
       "        0.63529414, 0.7921569 , 0.4509804 , 0.        , 0.8980392 ,\n",
       "        0.78039217, 0.4117647 , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.03529412, 0.69803923,\n",
       "        0.8       , 0.4509804 , 0.        , 0.4745098 , 0.5294118 ,\n",
       "        0.44705883, 0.45882353, 0.44705883, 0.44705883, 0.45882353,\n",
       "        0.4627451 , 0.46666667, 0.45882353, 0.44313726, 0.5764706 ,\n",
       "        0.24705882, 0.        , 0.88235295, 0.76862746, 0.41960785,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.07058824, 0.7058824 , 0.80784315, 0.5137255 ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.8784314 , 0.77254903, 0.48235294, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.5529412 , 0.5921569 , 0.29803923, 0.        , 0.00392157,\n",
       "        0.00392157, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.52156866, 0.654902  ,\n",
       "        0.28627452, 0.        , 0.        , 0.        ], dtype=float32),\n",
       " np.uint8(2))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# call to __getitem__:\n",
    "data[5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X1u-U7X-fXCB"
   },
   "source": [
    "But the above implementation still loads everything at the time of instantiation of the `FashionMNIST` class. So let's transform the data into a format that you see more often with big datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "EADlbbqB01Kw"
   },
   "outputs": [],
   "source": [
    "# unzip data:\n",
    "target_dir = 'data/data/fashion/unzipped'\n",
    "os.makedirs(target_dir, exist_ok=True)\n",
    "\n",
    "train = mnist_reader.load_mnist('data/data/fashion', kind='train')\n",
    "t10k  = mnist_reader.load_mnist('data/data/fashion', kind='t10k')\n",
    "\n",
    "data = np.concatenate((train[0], t10k[0]), axis=0)\n",
    "labels = np.concatenate((train[1], t10k[1]), axis=0)\n",
    "\n",
    "#enumerate()是用来同时获取循环中我们的可遍历对象的索引和值，返回一个迭代器对象，\n",
    "#可以在循环中使用\n",
    "for i, x in enumerate(data):\n",
    "    \n",
    "  #这一步是把所有图片一张一张取出来，\n",
    "  #然后保存到我们上面创建的unzip文件夹中，其中的i:d代表把每一个i转换成十进制的数\n",
    "  #其中的join方法是指把一个文件的路径进行链接，它会把多个路径片段组合成一个完整路径，\n",
    "  #确保中间的 / 或 \\ 正确（Mac Windows的分隔符不一样）\n",
    "  #这个npy文件numpy用来储存的文件，有着load方法和save方法\n",
    "  file = os.path.join(target_dir, f'img_{i:d}.npy')\n",
    "    \n",
    "  #以二进制写入（“wb”）的形式来把打开我们的file文件对象，并且把它保存为numpy数组\n",
    "  with open(file, 'wb') as f:\n",
    "    np.save(f, x.reshape((28, 28)))\n",
    "  \n",
    "    #.npy 是 NumPy 专用的二进制文件格式，用于保存数组数据。\n",
    "\n",
    "    #是由 numpy.save() 写入的\n",
    "\n",
    "    #读取用 numpy.load()\n",
    "#在循环外使用join，把我们的图片的标签进行储存，并且重新命名成为一个新的文件\n",
    "with open(os.path.join(target_dir, 'labels.npy'), 'wb') as f:\n",
    "  np.save(f, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lv0YptsZ-QaG",
    "outputId": "caa1e39a-6f7a-4795-8e76-012ba4e91000"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['img_0.npy',\n",
       " 'img_1.npy',\n",
       " 'img_10.npy',\n",
       " 'img_100.npy',\n",
       " 'img_1000.npy',\n",
       " 'img_10000.npy',\n",
       " 'img_10001.npy',\n",
       " 'img_10002.npy',\n",
       " 'img_10003.npy',\n",
       " 'img_10004.npy']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(target_dir)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FrICJqXvjc1Y"
   },
   "source": [
    "---\n",
    "\n",
    "<span style=\"color:red\"><b>TASK 2</b> - Dataset:</span>\n",
    "\n",
    "---\n",
    "\n",
    "Complete the following class.\n",
    "- It should load every single sample dynamically from disk when it is requested and this way keep memory consumption to a minimum.\n",
    "- Use your code from Task 1 to create stratified splits using the `stratify` and `shuffle` arguments of `create_split`.\n",
    "- Use the variable `target_dir` as the path to the unzipped data.\n",
    "- **Make sure it produces the the right type of outputs (see type hintig and class above)!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "VmiKviaXkHYb"
   },
   "outputs": [],
   "source": [
    "#这一个类的思想是：我们通过一个一个获取刚才我们解压的数据，来最小化性能的消耗，\n",
    "#避免死机的风险，这个类有两个参数，分别是int32类型的numpy数组indices\n",
    "#还有就是int8类型的numpy数组，labels。但是直接传参太麻烦了，我们写一个静态方法，\n",
    "#让我们直接使用类名.静态方法名()这样来方便的创建我们需要的测试集，验证集，训练集\n",
    "\n",
    "class FashionMNIST(Dataset):\n",
    "  def __init__(self, indices:NDArray[np.int32], labels:NDArray[np.int8]) -> None:\n",
    "    self.indices = indices\n",
    "    self.labels  = labels\n",
    "\n",
    "  def __len__(self) -> int:\n",
    "    return len(self.indices)\n",
    "\n",
    "#这里面首先定义一个i，这个i是我们前面解压的图片的编号，每一个图片只有i不同，\n",
    "#然后命名一个file_path用来生成并且存放图片的地址，因为我们的图片都是以npy格式储存的\n",
    "#所以说我们直接使用load方法加载图片，并且要记得除以255（像素范围为0-255），\n",
    "#得到0到1的数据，让神经网络方便学习，并且因为我们使用的是numpy数组来处理，所以要转化类型\n",
    "#为储存float32数据的numpy数组，float32更可以储存详细的图片的信息\n",
    "    \n",
    "#最后根据想要的索引获取我们的图片的标签\n",
    "#并且要转化成我们数字的格式方便神经网络使用    \n",
    "  def __getitem__(self, idx:int) -> int:\n",
    "      i = self.indices[idx]\n",
    "      file_path = os.path.join(target_dir, f'img_{i}.npy')\n",
    "      image = np.load(file_path).astype(np.float32)/255.0\n",
    "      label = int(self.labels[idx])\n",
    "      return image, label\n",
    "      \n",
    "      # complete\n",
    "\n",
    "#这个静态方法简化了我们的传参过程，并且还把数据划分为了我们需要的测试集、验证集、训练集\n",
    "#首先是找到我们解包的标签文件，转化成为数字类型（int8），然后用它来生成了我们的索引，\n",
    "#从0开始，一共有标签个的索引（也就是全部图片个数的索引）\n",
    "#然后我们进行判断，因为这个函数是否采用分层抽样是根据我们的标签决定的，\n",
    "#所以说只有判断我们输入了这个参数为True的情况下才可以对数据进行分层抽样\n",
    "  @staticmethod\n",
    "  def create_split(fraction_train:float, fraction_validation:float, fraction_test:float, stratify:bool=True, shuffle:bool=True) -> Tuple[Dataset, Dataset, Dataset]:\n",
    "    assert fraction_train + fraction_validation + fraction_test == 1.0\n",
    "    label_path = os.path.join(target_dir, 'labels.npy')\n",
    "    all_labels = np.load(label_path).astype(np.int8)\n",
    "    all_indeces = np.arange(len(all_labels), dtype=np.int32)\n",
    "\n",
    "    if stratify == True:\n",
    "        stratify_method = all_labels\n",
    "    else:\n",
    "        stratify_method = None\n",
    "        \n",
    "#我们的train_test_split()方法只能返回训练集和测试集，怎么办呢？ ：\n",
    "#我们用两次！先划分为训练集和剩余集，然后再在剩余集中划分我们的测试集和验证集\n",
    "      \n",
    "    idx_train, idx_rest, y_train, y_rest = train_test_split(               all_indeces, \n",
    "                                                                           all_labels,\n",
    "                                                                           train_size=fraction_train,\n",
    "                                                                           stratify= stratify_method,\n",
    "                                                                           shuffle=True,\n",
    "                                                                           random_state=42\n",
    "                                                            )\n",
    "    \n",
    "    rate_validation_rest = fraction_validation / (fraction_test + fraction_validation)\n",
    "      \n",
    "    if stratify == True:\n",
    "      stratify_method_rest = y_rest\n",
    "    else:\n",
    "      stratify_method_rest = None  \n",
    "    idx_validation, idx_test, y_validation, y_test = train_test_split(idx_rest,\n",
    "                                                                      y_rest,\n",
    "                                                                      train_size=rate_validation_rest,\n",
    "                                                                      stratify=stratify_method_rest,\n",
    "                                                                      shuffle=True,\n",
    "                                                                      random_state=42,        \n",
    "                                                                    )\n",
    "    #我们在这里进行各个集的划分，并且返回类的对象，\n",
    "    #这些数据集现在只有索引，没有数据，当需要的时候我们的数据才会加载到我们的内存。\n",
    "    data_train = FashionMNIST(idx_train, y_train)\n",
    "    data_valid = FashionMNIST(idx_validation, y_validation)\n",
    "    data_test = FashionMNIST(idx_test, y_test)\n",
    "    # complete\n",
    "    \n",
    "    return data_train, data_valid, data_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YQxU6CLfR7vD"
   },
   "source": [
    "---\n",
    "\n",
    "*End of Task 2. Copy your final code to **Homework 2 - Code** on **NextIlearn***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kRzLUn4kGGVU"
   },
   "source": [
    "Our objective is to create a model with the high accuracy on this dataset. Let's start to create our first model!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8ox0oodObDPH"
   },
   "source": [
    "**Shuffling and batching**: Using [`torch.utils.data.DataLoader`](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader), you can easily shuffle and batch the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "QdYJGAsARQxB"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "id": "BZmqQ9W2pp5b"
   },
   "outputs": [],
   "source": [
    "data_train, data_valid, data_test = FashionMNIST.create_split(.7, .1, .2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Epoch 是机器学习中一个完整的“遍历训练集的轮数”。\n",
    "#num_workers 是机器学习时候的线程数，可以设置为cpu的核心数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "W2dJNcKrESEU"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'DataLoader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m loader_train = \u001b[43mDataLoader\u001b[49m(data_train,             \u001b[38;5;66;03m# dataset from which to load the data. 数据从哪里来\u001b[39;00m\n\u001b[32m      2\u001b[39m                           batch_size=BATCH_SIZE,  \u001b[38;5;66;03m# how many samples per batch to load (default: 1). 一个分支多少个数据\u001b[39;00m\n\u001b[32m      3\u001b[39m                           shuffle=\u001b[38;5;28;01mTrue\u001b[39;00m,           \u001b[38;5;66;03m# set to True to have the data reshuffled at every epoch (default: False). 每一次划分是否打乱数据\u001b[39;00m\n\u001b[32m      4\u001b[39m                           sampler=\u001b[38;5;28;01mNone\u001b[39;00m,           \u001b[38;5;66;03m# defines the strategy to draw samples from the dataset. \u001b[39;00m\n\u001b[32m      5\u001b[39m                                                   \u001b[38;5;66;03m# Can be any Iterable with __len__ implemented. 如果不用shuffer随机打乱也想筛选数据\u001b[39;00m\n\u001b[32m      6\u001b[39m                                                   \u001b[38;5;66;03m# If specified, shuffle must not be specified. 和shuffle冲突\u001b[39;00m\n\u001b[32m      7\u001b[39m                           batch_sampler=\u001b[38;5;28;01mNone\u001b[39;00m,     \u001b[38;5;66;03m# like sampler, but returns a batch of indices at a time. \u001b[39;00m\n\u001b[32m      8\u001b[39m                                                   \u001b[38;5;66;03m# Mutually exclusive with batch_size, shuffle, sampler, and drop_last. 和sample类似，但是返回的是索引集合\u001b[39;00m\n\u001b[32m      9\u001b[39m                           drop_last=\u001b[38;5;28;01mFalse\u001b[39;00m)        \u001b[38;5;66;03m# set to True to drop the last incomplete batch, \u001b[39;00m\n\u001b[32m     10\u001b[39m                                                   \u001b[38;5;66;03m#if the dataset size is not divisible by the batch size. 如果最后一个数据不够batch，那么是否丢弃\u001b[39;00m\n\u001b[32m     11\u001b[39m                                                   \u001b[38;5;66;03m# If False and the size of dataset is not divisible by the batch size, \u001b[39;00m\n\u001b[32m     12\u001b[39m                                                   \u001b[38;5;66;03m#then the last batch will be smaller. (default: False)\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'DataLoader' is not defined"
     ]
    }
   ],
   "source": [
    "loader_train = DataLoader(data_train,             # dataset from which to load the data. 数据从哪里来\n",
    "                          batch_size=BATCH_SIZE,  # how many samples per batch to load (default: 1). 一个分支多少个数据\n",
    "                          shuffle=True,           # set to True to have the data reshuffled at every epoch (default: False). 每一次划分是否打乱数据\n",
    "                          sampler=None,           # defines the strategy to draw samples from the dataset. \n",
    "                                                  # Can be any Iterable with __len__ implemented. 如果不用shuffer随机打乱也想筛选数据\n",
    "                                                  # If specified, shuffle must not be specified. 和shuffle冲突\n",
    "                          batch_sampler=None,     # like sampler, but returns a batch of indices at a time. \n",
    "                                                  # Mutually exclusive with batch_size, shuffle, sampler, and drop_last. 和sample类似，但是返回的是索引集合\n",
    "                          drop_last=False)        # set to True to drop the last incomplete batch, \n",
    "                                                  #if the dataset size is not divisible by the batch size. 如果最后一个数据不够batch，那么是否丢弃\n",
    "                                                  # If False and the size of dataset is not divisible by the batch size, \n",
    "                                                  #then the last batch will be smaller. (default: False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "id": "Tj964nU9EVbq"
   },
   "outputs": [],
   "source": [
    "# validation set does not need to be repeated and shuffled since it all will be used at once - but MUST be batched.\n",
    "loader_valid = DataLoader(data_valid,\n",
    "                          batch_size=BATCH_SIZE,\n",
    "                          shuffle=False,\n",
    "                          sampler=None,\n",
    "                          batch_sampler=None,\n",
    "                          drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "id": "nu56t0MPO1PF"
   },
   "outputs": [],
   "source": [
    "# test set does not need to be repeated and shuffled since it all will be used at once - but MUST be batched.\n",
    "loader_test  = DataLoader(data_test,\n",
    "                          batch_size=BATCH_SIZE,\n",
    "                          shuffle=False,\n",
    "                          sampler=None,\n",
    "                          batch_sampler=None,\n",
    "                          drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#为什么我们要使用多个batch呢？\n",
    "# 1.数据量很大，我们的测试集、训练集、验证集都是大数据，\n",
    "#不使用batch分块的话很容易爆内存\n",
    "\n",
    "# 2.我们的训练集，每一个训练轮回（epoch）都要进行数据的打乱，\n",
    "#不然模型可能会学到我们的数据的顺序\n",
    "\n",
    "# 3.验证集，测试集，是因为他们的数据量大，但是他们只会使用一次进行评估模型的表现以及调试参数，\n",
    "#所以说我们也要使他们划分成batch但是不进行shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ewz-SbwJxZ1t"
   },
   "source": [
    "### Section 2: Sequential fully connected network （如何创建一个全连接神经网络）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8Fh7PjMWqOnS"
   },
   "source": [
    "#### Instantiating the network（实例化网络模型/创建网络）:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xGuxZ7HZgpwm"
   },
   "source": [
    "The standard way to create a PyTorch model is to override the [`torch.nn.Module`](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module) class. To create a model you need to override the following methods:\n",
    "- `__init__(self, ...) -> None`: Initializes the module and instantiates all the layers and functions.\n",
    "- `forward(self, x) -> y`: implements the forward pass through the network.\n",
    "\n",
    "When you create a layer (e.g. [`torch.nn.Linear`](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear)), you should specify **in_features** and **out_features**. Don't forget to apply an **activation function** in the forward pass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#在init方法中我们应该创建我们的神经网络的每一层线性层，每一层线性层！\n",
    "#在forward方法中是我们在神经网络进行的过程的激活函数的添加，为我们的函数添加非线性特性\n",
    "\n",
    "#运行的顺序，在我们初始化模型后，首先调用了__init__()方法，\n",
    "#这样会创建我们的神经网络的每一层，并且以属性的形式储存在我们的模型对象中\n",
    "\n",
    "#我们在创建了我们的神经网络对象后，使用对象名(参数)的方式，\n",
    "#这样会被Model中的__call__方法拦截，调用我们的forward方法，实现我们的网络的非线性化以及输出结果的操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "dpDMjCbExvzN"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "#Fashion MNIST 中的图像是：\n",
    "#每张图像大小：28 × 28 像素\n",
    "#是灰度图（1 个通道）\n",
    "#但神经网络的全连接层需要一维向量作为输入，所以你要先把图像展平成一维，输入in_features = 784\n",
    "#我们的隐藏层（hidden_size）的通常取值有：64，128，256，512，\n",
    "#值越大我们的模型越细致，越容易过拟合以及训练时间更长\n",
    "\n",
    "#outer_features一般是我们的的数据有多少类就选择多少，比如我们的这个数据集里面，\n",
    "#我们的数据一共有10类，那么我们的outer_features一般建议选择10\n",
    "#bias是指我们的神经网络的这一层是否加入偏置项\n",
    "\n",
    "class CustomNetwork(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        #必须调用父类的这个方法，因为它实际上是把nn.Module中的神经网络相关的方法加载进了我们的项目，我们要使用这些功能\n",
    "        super().__init__()\n",
    "        #我们定义了一个神经网络中间层的线性对象，赋值给了我们当前神经网络模型的属性layer1\n",
    "        self.layer1 = nn.Linear(in_features=784, out_features=100, bias=True)\n",
    "        #这里的in_features是上面一层输入的100\n",
    "        self.layer2 = nn.Linear(in_features=100, out_features=len(class_names), bias=True)\n",
    "\n",
    "    def forward(self, x:pt.Tensor) -> pt.Tensor:\n",
    "        #这里是定义了第一层的输出，我们的输出实际上是self.layer1，但是他是线性的，\n",
    "        #要在forward里面加上激活函数\n",
    "\n",
    "        #为什么我们的self.layer1/2明明是一个属性，还是可以像函数一样调用？\n",
    "        #因为我们的父类实现了__call__方法，所以可以直接把对象当成函数使用，注意我们的对象是（self.layer1/2）\n",
    "        #所以self.layer1/2 实际上是等于： nn.Linear(), 我们使用了实现了call方法，\n",
    "        #所以下面这一句话等于 F.relu(nn.Linear().__call__(x))\n",
    "        x = F.relu(self.layer1(x))\n",
    "        return F.softmax(self.layer2(x), dim=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wvjomL9CJcrr"
   },
   "source": [
    "We can visualize the model using **keras.utils.plot_model**. It helps to figue out (or validate) the structure of complete models having multiple paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-iLn73SNJenS",
    "outputId": "6783da1f-b7c8-4f0b-faed-fc7b2cf4df5e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1                  [-1, 100]          78,500\n",
      "            Linear-2                   [-1, 10]           1,010\n",
      "================================================================\n",
      "Total params: 79,510\n",
      "Trainable params: 79,510\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.00\n",
      "Params size (MB): 0.30\n",
      "Estimated Total Size (MB): 0.31\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "\n",
    "model = CustomNetwork()\n",
    "#这里的input_size必须接受一个元组，\n",
    "#这个元组的结构为：(数据的个数，数量通道数, 高度, 宽度)，\n",
    "#这里是一个单通道的一维向量，所以输入（784，） \n",
    "summary(model, input_size=(784,), device='cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S_iVtGfSEe7b"
   },
   "source": [
    "Summarization of model parameters is only possible when the model has an input information as it needs to calculate the fully connected parameters from the input layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZEOcLYKLEpgw"
   },
   "source": [
    "A model instance has various attributes to get layers, weights - which are just for your reference to check the real values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A5iYpVqcwYL9",
    "outputId": "7155a52e-122b-4c8c-ed89-674a251e53d7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Linear(in_features=784, out_features=100, bias=True),\n",
       " Linear(in_features=100, out_features=10, bias=True)]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You can get a generator object of properties of type `torch.nn.Module` using `children()`:\n",
    "# !!! in order of instantiation !!!\n",
    "list(model.children())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bFwCNTJ4nGyW",
    "outputId": "8e7848df-a758-4acd-88eb-73bb9151334b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('layer1', Linear(in_features=784, out_features=100, bias=True)),\n",
       " ('layer2', Linear(in_features=100, out_features=10, bias=True))]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.named_children())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WJcb7xZtpEAZ",
    "outputId": "cd38ff45-61ec-40b1-c503-b40294f452f7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=784, out_features=100, bias=True)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_submodule('layer1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SdnS08_Lom1s",
    "outputId": "8f783847-a0b2-4331-d09f-bff8f096f741"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('',\n",
       "  CustomNetwork(\n",
       "    (layer1): Linear(in_features=784, out_features=100, bias=True)\n",
       "    (layer2): Linear(in_features=100, out_features=10, bias=True)\n",
       "  )),\n",
       " ('layer1', Linear(in_features=784, out_features=100, bias=True)),\n",
       " ('layer2', Linear(in_features=100, out_features=10, bias=True))]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# All modules in the model (including itself):\n",
    "list(model.named_modules())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lAa1OQuPnlNF",
    "outputId": "ce9fadd4-012c-4627-b3cd-6ebf3299510b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[-0.0082, -0.0251,  0.0126,  ..., -0.0104,  0.0314,  0.0181],\n",
       "         [-0.0200,  0.0178, -0.0053,  ...,  0.0121, -0.0273,  0.0209],\n",
       "         [-0.0253,  0.0153, -0.0076,  ...,  0.0234,  0.0111,  0.0129],\n",
       "         ...,\n",
       "         [ 0.0354,  0.0019, -0.0270,  ...,  0.0039,  0.0096,  0.0071],\n",
       "         [-0.0334,  0.0171, -0.0323,  ..., -0.0190,  0.0126,  0.0099],\n",
       "         [-0.0011, -0.0146, -0.0234,  ..., -0.0103,  0.0257,  0.0074]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([ 0.0211,  0.0289, -0.0188,  0.0356,  0.0275,  0.0307,  0.0247, -0.0296,\n",
       "          0.0041, -0.0209, -0.0175,  0.0339, -0.0271, -0.0135,  0.0189,  0.0156,\n",
       "          0.0116, -0.0127,  0.0302, -0.0151, -0.0293,  0.0357, -0.0095,  0.0249,\n",
       "         -0.0241,  0.0285, -0.0244, -0.0178, -0.0166,  0.0344, -0.0095, -0.0326,\n",
       "          0.0357, -0.0066, -0.0185, -0.0087, -0.0028, -0.0357,  0.0236, -0.0232,\n",
       "         -0.0204,  0.0350,  0.0060,  0.0330,  0.0316,  0.0221,  0.0306,  0.0163,\n",
       "          0.0341, -0.0301,  0.0104,  0.0285, -0.0209, -0.0210,  0.0182,  0.0162,\n",
       "          0.0321,  0.0127, -0.0302, -0.0167, -0.0260, -0.0223, -0.0328, -0.0247,\n",
       "         -0.0074,  0.0154, -0.0318, -0.0046,  0.0127, -0.0057,  0.0166,  0.0287,\n",
       "          0.0056, -0.0290, -0.0132, -0.0333, -0.0112,  0.0188, -0.0200,  0.0295,\n",
       "          0.0245, -0.0330,  0.0208,  0.0240, -0.0047,  0.0149,  0.0132, -0.0130,\n",
       "          0.0230,  0.0306, -0.0169, -0.0346,  0.0006,  0.0176,  0.0337, -0.0028,\n",
       "          0.0031, -0.0132,  0.0169, -0.0261], requires_grad=True)]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You can get a generator object of parameters (weights) for each submodule using `parameters()`:\n",
    "# !!! in order of instantiation !!!\n",
    "list(model.parameters())[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bUW334iaoA7z",
    "outputId": "cddc0c0f-a251-4b24-a385-f682a0a4eed1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('layer1.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[-0.0082, -0.0251,  0.0126,  ..., -0.0104,  0.0314,  0.0181],\n",
       "          [-0.0200,  0.0178, -0.0053,  ...,  0.0121, -0.0273,  0.0209],\n",
       "          [-0.0253,  0.0153, -0.0076,  ...,  0.0234,  0.0111,  0.0129],\n",
       "          ...,\n",
       "          [ 0.0354,  0.0019, -0.0270,  ...,  0.0039,  0.0096,  0.0071],\n",
       "          [-0.0334,  0.0171, -0.0323,  ..., -0.0190,  0.0126,  0.0099],\n",
       "          [-0.0011, -0.0146, -0.0234,  ..., -0.0103,  0.0257,  0.0074]],\n",
       "         requires_grad=True)),\n",
       " ('layer1.bias',\n",
       "  Parameter containing:\n",
       "  tensor([ 0.0211,  0.0289, -0.0188,  0.0356,  0.0275,  0.0307,  0.0247, -0.0296,\n",
       "           0.0041, -0.0209, -0.0175,  0.0339, -0.0271, -0.0135,  0.0189,  0.0156,\n",
       "           0.0116, -0.0127,  0.0302, -0.0151, -0.0293,  0.0357, -0.0095,  0.0249,\n",
       "          -0.0241,  0.0285, -0.0244, -0.0178, -0.0166,  0.0344, -0.0095, -0.0326,\n",
       "           0.0357, -0.0066, -0.0185, -0.0087, -0.0028, -0.0357,  0.0236, -0.0232,\n",
       "          -0.0204,  0.0350,  0.0060,  0.0330,  0.0316,  0.0221,  0.0306,  0.0163,\n",
       "           0.0341, -0.0301,  0.0104,  0.0285, -0.0209, -0.0210,  0.0182,  0.0162,\n",
       "           0.0321,  0.0127, -0.0302, -0.0167, -0.0260, -0.0223, -0.0328, -0.0247,\n",
       "          -0.0074,  0.0154, -0.0318, -0.0046,  0.0127, -0.0057,  0.0166,  0.0287,\n",
       "           0.0056, -0.0290, -0.0132, -0.0333, -0.0112,  0.0188, -0.0200,  0.0295,\n",
       "           0.0245, -0.0330,  0.0208,  0.0240, -0.0047,  0.0149,  0.0132, -0.0130,\n",
       "           0.0230,  0.0306, -0.0169, -0.0346,  0.0006,  0.0176,  0.0337, -0.0028,\n",
       "           0.0031, -0.0132,  0.0169, -0.0261], requires_grad=True))]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.named_parameters())[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vyjmrnDXobxo",
    "outputId": "3e22976d-f24c-4a97-b81e-3c52cae159be"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.0082, -0.0251,  0.0126,  ..., -0.0104,  0.0314,  0.0181],\n",
       "        [-0.0200,  0.0178, -0.0053,  ...,  0.0121, -0.0273,  0.0209],\n",
       "        [-0.0253,  0.0153, -0.0076,  ...,  0.0234,  0.0111,  0.0129],\n",
       "        ...,\n",
       "        [ 0.0354,  0.0019, -0.0270,  ...,  0.0039,  0.0096,  0.0071],\n",
       "        [-0.0334,  0.0171, -0.0323,  ..., -0.0190,  0.0126,  0.0099],\n",
       "        [-0.0011, -0.0146, -0.0234,  ..., -0.0103,  0.0257,  0.0074]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_parameter('layer1.weight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "06cXyZlQwJca"
   },
   "source": [
    "---\n",
    "\n",
    "<span style=\"color:red\"><b>TASK 3</b> - Simple Network:</span>\n",
    "\n",
    "---\n",
    "\n",
    "The above network is very simple. Implement a better version with the following layers:\n",
    "- One **linear input layer** of 300 perceptrons, with a **ReLu** activation function, followed by a **dropout** layer (use the `dropout` parameter for the ratio).\n",
    "- One **linear hidden layers** of size 200, with a **ReLu** activation function, followed by **dropout** layers (use the `dropout` parameter for the ratio).\n",
    "- One **linear output layer**, with a **softmax** activation function.\n",
    "\n",
    "Assume that `torch.nn` is already imported as `nn`. Furthermore, `torch.nn.functional` is available as `F`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "vpYsDHgzwuwI"
   },
   "outputs": [],
   "source": [
    "class CustomNetwork(nn.Module):\n",
    "    def __init__(self, dropout:float=.2) -> None:\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Linear(in_features= 784, out_features= 300, bias= True)\n",
    "        self.dropout1 = nn.Dropout(p= dropout)\n",
    "        self.layer2 = nn.Linear(in_features= 300, out_features= 200, bias= True)\n",
    "        self.dropout2 = nn.Dropout(p= dropout)\n",
    "        self.output = nn.Linear(in_features= 200, out_features= 10, bias= True)\n",
    "        #continue\n",
    "\n",
    "    def forward(self, x:pt.Tensor) -> pt.Tensor:\n",
    "        x = F.relu(self.layer1(x))\n",
    "        x = self.dropout1(x)\n",
    "        x = F.relu(self.layer2(x))\n",
    "        x = self.dropout2(x)\n",
    "        x = F.softmax(self.output(x), dim = -1)\n",
    "        return x \n",
    "        #continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-yN435-5R7vM"
   },
   "source": [
    "---\n",
    "\n",
    "*End of Task 3. Copy your final code to **Homework 2 - Code** on **NextIlearn***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Alternative but more restrictive:** `torch.nn.Sequential`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 为什么说更加的有着局限性？\n",
    "1.无法写出复杂的前向逻辑\n",
    "\n",
    "2.无法传入额外的参数例如：forward(x, y)\n",
    "\n",
    "3.无法访问中间层（隐藏层）的输出\n",
    "\n",
    "4.不方便调试，因为无法查看每一层的行为"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Sequential"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unnamed layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential(\n",
    "    nn.Linear(in_features=784, out_features=100, bias=True),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(in_features=100, out_features=len(class_names), bias=True),\n",
    "    nn.Softmax(dim=-1)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Named layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "\n",
    "model = Sequential(\n",
    "    OrderedDict([\n",
    "        ('layer1',      nn.Linear(in_features=784, out_features=100, bias=True)),\n",
    "        ('activation1', nn.ReLU()),\n",
    "        ('layer2',      nn.Linear(in_features=100, out_features=len(class_names), bias=True)),\n",
    "        ('activation2', nn.Softmax(dim=-1))])\n",
    "                  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aWo7nYEYp-Wb"
   },
   "source": [
    "### Section 3: Training the network:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g2Q14ZHssu1E"
   },
   "source": [
    "In PyTorch one needs to define which device to use for computation. All tensors involved in the computation need to be on that device. The most common devices are:\n",
    "- `cpu`: any of your computer's CPUs\n",
    "- `cpu:0`:the first of your computer's CPUs\n",
    "- `cuda`: any of your computer's GPUs\n",
    "- `cuda:2`: the third GPU of you computer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B9HxsXGisi9T",
    "outputId": "9d9b00c4-3688-430a-c018-9103e0ee85a1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get gpu if available else cpu:\n",
    "device = pt.device(\"cuda\" if pt.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "qs-4FS3uKsMZ"
   },
   "outputs": [],
   "source": [
    "# move a model or tensor to the device:\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zuZAZKxtFBFR"
   },
   "source": [
    "Prediction on new instances:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#什么是张量（tensor）？是在pytorch中使用的一种数据类型，\n",
    "#可以用来储存任何的数据（图片，文字，矩阵等）,在pytorch中，所有的数据操作都是依赖于\n",
    "#张量（tensor）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SdDh74y0i7fX",
    "outputId": "3540b42b-4dc9-4ec4-e0b2-2991c8681b63"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.10359176, 0.10316145, 0.10157386, 0.10771481, 0.10815857,\n",
       "        0.09387175, 0.09968138, 0.09457639, 0.08892886, 0.09874113],\n",
       "       [0.10374948, 0.10163356, 0.09320676, 0.10409319, 0.09297819,\n",
       "        0.10371773, 0.08816293, 0.10435402, 0.09117378, 0.11693045],\n",
       "       [0.09568685, 0.10134783, 0.10292954, 0.1086219 , 0.11608744,\n",
       "        0.09458002, 0.09785486, 0.08976703, 0.08561835, 0.10750625]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new = pt.tensor(X_test[:3], dtype=pt.float32, device=device)\n",
    "y_proba = model(X_new) # this returns a probability?\n",
    "#下面这一步使用了detach()方法摘除张量和我们的计算图的联系，把张量转化成numpy数组\n",
    "y_proba = y_proba.detach().cpu().numpy() # to numpy\n",
    "y_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nU8cAN3fi99y",
    "outputId": "f926d9e3-d1de-4e9b-c668-a5f69af07076"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Coat', 'Ankle boot', 'Coat'], dtype='<U11')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(class_names)[np.argmax(y_proba, axis=1)] #if we want to know the class names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y9wLOuG8vK_r"
   },
   "source": [
    "Instances of `torch.nn.Module` have a method `.train()` and a method `.eval()` that set the whole module (including submodules) in a training or prediction mode.\n",
    "\n",
    "This is necessary, as for example dropout layers are inactive during prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hIRxMYLRqnoU"
   },
   "source": [
    "In order to train the network, we need to define a training procedure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#我们的训练模式和预测模式中，dropout和batch的行为不同\n",
    "#训练模式：dropout会随机丢弃神经元，batch会使用当前的batch进行统计\n",
    "#预测模式：dropout不会进行丢弃操作，batch会使用训练好的参数\n",
    "#注意，我们的batch不仅有着分块的作用，还有着统计的作用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "id": "FqjxNg_mDP2z"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score\n",
    "from typing import Optional, Callable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "aBxz4ZXkz4hT"
   },
   "outputs": [],
   "source": [
    "#我们的epoch函数是代表单次训练轮次，接受的参数有，我们的神经网络模型，数据加载器，\n",
    "#优化器（更新参数，减少我们的loss），损失函数(衡量我们的模型和真实模型之间的差距的函数)\n",
    "\n",
    "\n",
    "def epoch(model:CustomNetwork, loader_train:DataLoader, optimizer:pt.optim.Optimizer, loss_fn:Callable[[pt.Tensor, pt.Tensor], pt.Tensor]):\n",
    "  # 1. set model to train:（转换成训练模式，因为我们的训练模式和预测模式的dropout等会不一样）\n",
    "  model.train()\n",
    "    \n",
    "  #如果没有传入 loss function，losses 就设为 None\n",
    "  #否则就初始化为空列表，用来记录每个 batch 的 loss\n",
    "    \n",
    "  losses = None if loss_fn is None else []\n",
    "  \n",
    "  #开启梯度计算环境\n",
    "  with pt.enable_grad():\n",
    "\n",
    "    #会自动从数据加载器（dataloader）中提取出我们设定好的一个brach，\n",
    "    #这里提取了一个brach中的数据和标签，我们的自定义数据类返回的是一个元组，包含着数据和标签\n",
    "    for X_batch, y_batch in loader_train:\n",
    "      #展平数据，我们应该展平我们的数据，全连接层要求就是这样，输入只能是一个一维的向量\n",
    "      #首先我们可以使用reshape或者是view方法，都可以，其中shape方法返回我们的向量的数量，\n",
    "      #和向量的通道，向量的组成，所以我们取第一个，我们保持向量数量不变\n",
    "      #再把所有的向量的特征展开到一维上，也就是在后面的参数使用-1，让pytorch自动处理匹配我们的维度\n",
    "      X_batch = X_batch.view(X_batch.shape[0], -1)\n",
    "\n",
    "      #我们的y已经是一维向量了，不用重新匹配维度\n",
    "        \n",
    "      # move tensors to correct device:\n",
    "      #把数据移动到正确的设备中去（cpu, gpu），为什么？\n",
    "      #因为pytorch中我们的数据和训练/评估数据的时候我们的数据和模型必须在同一个设备中\n",
    "      X_batch = X_batch.to(device)\n",
    "      y_batch = y_batch.to(device)\n",
    "\n",
    "      # reset all gradients to zero:\n",
    "      #只有在使用了backward()的时候才会计算梯度，但是我们的梯度会一直储存着，\n",
    "      #如果不用zero_grad清空，我们的梯度会一直增加，第一次循环没有梯度，但是第二次循环开始\n",
    "      #是存在着梯度的，所以说我们管他的先手动清除一次梯度再说\n",
    "      optimizer.zero_grad()\n",
    "\n",
    "      # create predictions:\n",
    "      #将我们的当前的batch中的内容输入进我们的模型，然后使用模型预测出我们的概率\n",
    "      y_pred = model(X_batch)\n",
    "\n",
    "      # calculate loss:\n",
    "      #这里是在使用我们这个batch预测的标签和真正的标签来得到我们当前batch总体的平均损失值\n",
    "      loss = loss_fn(y_pred, y_batch)\n",
    "        \n",
    "      #这里是使用detach方法解除我们的损失和图像的链接，然后把损失放入我们的cpu运行，\n",
    "      #再把损失转化成numpy数组，因为在gpu中转化成numpy会报错\n",
    "      #这里是在我们之前定义的losses列表中储存当前的batch的平均损失值，\n",
    "      #为什么用append呢，因为我们的损失值是float类型，使用extend会报错\n",
    "      #extend方法的对象必须是一个可迭代的对象，loss不能使用extend\n",
    "      losses.append(loss_fn(y_pred, y_batch).detach().cpu().numpy())\n",
    "\n",
    "      # backpropagate loss:\n",
    "      #计算我们在当前的batch的模型的每一个参数的梯度\n",
    "      loss.backward()\n",
    "\n",
    "      # update weights:\n",
    "      #使用刚刚计算好的梯度更新我们的模型的参数\n",
    "      optimizer.step()\n",
    "  \n",
    "  #返回我们这一轮（epoch）训练的loss的平均值，以便我们之后判断我们的模型是否过拟合或者是否可以提早终止训练\n",
    "  return np.mean(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "id": "adSjw6i50L3b"
   },
   "outputs": [],
   "source": [
    "#函数接受三个参数，我们已经定义的神经网络模型，\n",
    "#使用dataloader加载的验证数据集，以及使用Optional修饰的损失函数，代表我们可以选择写或者不写\n",
    "#里面Callable代表中括号里面的值都是实现了__call__的对象，接受两个张量返回一个张量\n",
    "\n",
    "def evaluate(model:CustomNetwork, loader_valid:DataLoader, loss_fn:Optional[Callable[[pt.Tensor, pt.Tensor], pt.Tensor]]=None):\n",
    "  # 1. set model to eval:\n",
    "  #设置我们的模型为评估模式\n",
    "  model.eval()\n",
    "\n",
    "  #创建列表labels储存我们的真实的标签，predictions储存我们的神经网络模型预测的值，\n",
    "  #如果我们传入了损失函数，那么创建一个空列表来储存计算出的loss\n",
    "  labels = []\n",
    "  predictions = []\n",
    "  losses = None if loss_fn is None else []\n",
    "\n",
    "  #和我们的epoch中的含义相同，读取当前的batch中的数据和标签\n",
    "  for X_batch, y_batch in loader_valid:\n",
    "    #展平数据，我们应该展平数据，不然会报错\n",
    "    X_batch = X_batch.view(X_batch.shape[0], -1)\n",
    "      \n",
    "    # move tensors to correct device:\n",
    "    #作用是把数据和模型一起放到相同的设备中\n",
    "    X_batch = X_batch.to(device)\n",
    "    y_batch = y_batch.to(device)\n",
    "\n",
    "    #提取出我们的标签的numpy数组，并且因为这个数组实际上是这样的结构[a, b, c],\n",
    "    #所以使用extend将它迭代之后逐渐存入我们的标签数组，虽然这样会导致我们每一个batch\n",
    "    #的标签的边界不好判断，但是通常我们都是使用一维标签数组来判断模型整体的效果\n",
    "    labels.extend(y_batch.cpu().detach().numpy())\n",
    "\n",
    "    # create predictions:\n",
    "    #进行模型的评估，得到我们的模型预测的结果（概率），并且加入储存预测label的空列表中\n",
    "    y_pred = model(X_batch)\n",
    "    predictions.extend(y_pred.cpu().detach().numpy())\n",
    "\n",
    "    # calculate loss:\n",
    "    #使用我们的损失函数来计算我们的loss，并且储存它们到空列表中\n",
    "    #注意我们不是在进行模型的训练，不需要进行梯度的计算以及模型参数的更新，也就是不用backward以及step\n",
    "    if loss_fn is not None:\n",
    "      losses.append(loss_fn(y_pred, y_batch).detach().cpu().numpy())\n",
    "\n",
    "  # calculate f1 score:\n",
    "  f1 = f1_score(\n",
    "    #将我们的实际的标签转化成numpy数组\n",
    "    #y_batch.cpu().detach().numpy(),这一句有错误，我们的计算f1在函数外，\n",
    "    #只会计算一次，而我们把所有的标签，预测储存就是为了一次计算\n",
    "    #这里的标签其实时从0-9，代表不同的类\n",
    "    np.array(labels),\n",
    "      \n",
    "    #将我们的预测结果使用argmax取最大值，其中dim=1代表了我们此时取的是列上面的最大值，这一步是得到我们的模型预测的标签\n",
    "    #我们模型预测的结果是一个张量，里面包含了每一个样本在不同类别中的得分，所以说我们要选出最高分，这样才代表了我们预测的标签\n",
    "    #为什么dim=1?因为我们的张量实际上有着样本个数的样本，每一个样本都是一个列表，有着10个（因为有十类标签）得分，\n",
    "    #所以说选择得分最高的一列做标签而不是dim=0，这样没有意义\n",
    "    #y_pred.argmax(dim=1).cpu().detach().numpy(),这一句是错误的，我们使用储存好的预测数组进行我们f1分数的计算\n",
    "    #argmax(axis = 1 )代表在这个数组中每一行中寻找最大的列的索引，返回一个numpy数组\n",
    "    np.array(predictions).argmax(axis=1),\n",
    "    #对每个标签类别单独计算F1分数，然后取所有类别F1的平均值\n",
    "    average='macro'\n",
    "  )\n",
    "\n",
    "  if loss_fn is None: return {'f1':f1}\n",
    "  else: return {'loss':np.mean(losses), 'f1':f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "id": "SASZ5PCXq4tr"
   },
   "outputs": [],
   "source": [
    "#这里是定义了一个训练函数，我们的模型重复训练多轮并且在每一轮训练后都会进行验证，\n",
    "#记录我们的f1分数后返回到所有的轮次的训练过程\n",
    "\n",
    "def fit(model:CustomNetwork, loader_train:DataLoader, loader_valid:DataLoader, epochs:int, lr:float):\n",
    "  # instantiate optimizer:\n",
    "  #初始化我们的优化器，，指定我们的优化器是随机梯度下降，然后我们的参数是模型的参数，\n",
    "  #学习率（下降程度）\n",
    "    \n",
    "  #其中的parameters()方法是我们继承的方法，返回我们优化器需要调整的各个参数，\n",
    "  #lr是我们的学习率，需要谨慎调节\n",
    "  optimizer = pt.optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "  # instantiate loss function:\n",
    "  #初始化损失函数，这个损失函数适用于多分类问题\n",
    "  loss_fn = pt.nn.CrossEntropyLoss()\n",
    "\n",
    "  #用来记录我们每一轮训练的训练loss，验证loss，验证f1分数\n",
    "  history = []\n",
    "    \n",
    "  #遍历我们的训练轮数\n",
    "  for i in range(epochs):\n",
    "    # train for one epoch:\n",
    "    #根据我们上面写的方法来执行我们一轮训练，并且获取训练的loss\n",
    "    loss_train = epoch(model, loader_train, optimizer, loss_fn)\n",
    "\n",
    "    # evaluate on validation:\n",
    "    #此时评估我们经过这一轮训练时的模型\n",
    "    metrics = evaluate(model, loader_valid, loss_fn)\n",
    "\n",
    "    # save metrics:\n",
    "    #把我们这一轮训练的训练损失，验证损失，以及验证f1分数保存起来\n",
    "    history.append({\n",
    "      'loss_train':loss_train,\n",
    "      'loss_valid': metrics['loss'],\n",
    "      'f1_valid': metrics['f1']\n",
    "    })\n",
    "\n",
    "    # print message:\n",
    "    #打印当前训练的结果\n",
    "    print(f'Epoch {i+1:d}/{epochs:d}:', *[f'{metric} = {history[-1][metric]:.2f};' for metric in history[-1]], sep='\\t')\n",
    "\n",
    "  # return history:\n",
    "  return pd.DataFrame(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q08uZrmWMCmq"
   },
   "source": [
    "Fit the model for 30 epochs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "U1VqXewrMCVQ",
    "outputId": "83b21833-f6f7-4424-ac0d-49c4334032c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30:\tloss_train = 2.28;\tloss_valid = 2.23;\tf1_valid = 0.07;\n",
      "Epoch 2/30:\tloss_train = 2.14;\tloss_valid = 2.01;\tf1_valid = 0.39;\n",
      "Epoch 3/30:\tloss_train = 1.92;\tloss_valid = 1.84;\tf1_valid = 0.60;\n",
      "Epoch 4/30:\tloss_train = 1.83;\tloss_valid = 1.80;\tf1_valid = 0.60;\n",
      "Epoch 5/30:\tloss_train = 1.79;\tloss_valid = 1.76;\tf1_valid = 0.66;\n",
      "Epoch 6/30:\tloss_train = 1.77;\tloss_valid = 1.74;\tf1_valid = 0.71;\n",
      "Epoch 7/30:\tloss_train = 1.74;\tloss_valid = 1.72;\tf1_valid = 0.73;\n",
      "Epoch 8/30:\tloss_train = 1.72;\tloss_valid = 1.70;\tf1_valid = 0.74;\n",
      "Epoch 9/30:\tloss_train = 1.71;\tloss_valid = 1.69;\tf1_valid = 0.74;\n",
      "Epoch 10/30:\tloss_train = 1.70;\tloss_valid = 1.69;\tf1_valid = 0.75;\n",
      "Epoch 11/30:\tloss_train = 1.69;\tloss_valid = 1.68;\tf1_valid = 0.75;\n",
      "Epoch 12/30:\tloss_train = 1.69;\tloss_valid = 1.68;\tf1_valid = 0.75;\n",
      "Epoch 13/30:\tloss_train = 1.68;\tloss_valid = 1.67;\tf1_valid = 0.76;\n",
      "Epoch 14/30:\tloss_train = 1.68;\tloss_valid = 1.67;\tf1_valid = 0.76;\n",
      "Epoch 15/30:\tloss_train = 1.68;\tloss_valid = 1.67;\tf1_valid = 0.76;\n",
      "Epoch 16/30:\tloss_train = 1.68;\tloss_valid = 1.67;\tf1_valid = 0.76;\n",
      "Epoch 17/30:\tloss_train = 1.67;\tloss_valid = 1.66;\tf1_valid = 0.77;\n",
      "Epoch 18/30:\tloss_train = 1.67;\tloss_valid = 1.66;\tf1_valid = 0.77;\n",
      "Epoch 19/30:\tloss_train = 1.67;\tloss_valid = 1.66;\tf1_valid = 0.77;\n",
      "Epoch 20/30:\tloss_train = 1.67;\tloss_valid = 1.66;\tf1_valid = 0.77;\n",
      "Epoch 21/30:\tloss_train = 1.67;\tloss_valid = 1.66;\tf1_valid = 0.77;\n",
      "Epoch 22/30:\tloss_train = 1.66;\tloss_valid = 1.66;\tf1_valid = 0.77;\n",
      "Epoch 23/30:\tloss_train = 1.66;\tloss_valid = 1.66;\tf1_valid = 0.77;\n",
      "Epoch 24/30:\tloss_train = 1.66;\tloss_valid = 1.66;\tf1_valid = 0.77;\n",
      "Epoch 25/30:\tloss_train = 1.66;\tloss_valid = 1.65;\tf1_valid = 0.77;\n",
      "Epoch 26/30:\tloss_train = 1.66;\tloss_valid = 1.65;\tf1_valid = 0.78;\n",
      "Epoch 27/30:\tloss_train = 1.66;\tloss_valid = 1.65;\tf1_valid = 0.78;\n",
      "Epoch 28/30:\tloss_train = 1.66;\tloss_valid = 1.65;\tf1_valid = 0.78;\n",
      "Epoch 29/30:\tloss_train = 1.66;\tloss_valid = 1.65;\tf1_valid = 0.78;\n",
      "Epoch 30/30:\tloss_train = 1.65;\tloss_valid = 1.65;\tf1_valid = 0.78;\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='epoch', ylabel='loss'>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# instantiate model and move to device:\n",
    "model = CustomNetwork().to(device)\n",
    "\n",
    "# train model:\n",
    "history = fit(model, loader_train, loader_valid, epochs=30, lr=.01)\n",
    "\n",
    "# plot history:\n",
    "history[['loss_train', 'loss_valid']].plot(xlabel='epoch', ylabel='loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#评估该图：我们的训练集损失和测试集损失差不多，比较贴合，\n",
    "#没有过拟合发生；并且两个线都在稳步下降，说明我们的模型在学习，误差在变小"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6qmHUt5M_nQd"
   },
   "source": [
    "**Evaluation**: `evaluate` will return the metric scores!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PMdArSMDi8BI",
    "outputId": "18d52ab3-0877-4be2-8958-1f8dd4c02219"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'f1': 0.7770619877272422}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(model, loader_test) #evaluate on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#有没有想过我们的测试集，训练集，评估集都在干什么？\n",
    "#我们训练神经网络模型有2阶段，第一个是模型调试阶段，\n",
    "#我们的模型使用训练集训练n回，每一次都使用评估集进行一次的评估，得到评估的分数\n",
    "#在进行完了训练评估过程后，绘图查看到我们的loss反复跳变的点后，\n",
    "#就可以证明，我们的最佳参数就在这个范围内"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How does SGD work?\n",
    "\n",
    "<img src=\"https://pantelis.github.io/cs677/docs/common/lectures/optimization/sgd/images/gradient-descent.png\" alt=\"gradient-descent.png\" style=\"width:500px;\"/>\n",
    "\n",
    "Can be improved by:\n",
    " - ... reducing the stepsize (i.e. `lr`) towards the end\n",
    " - ... using momentum to keep a clear trajectory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LcSUB0uJTPBg"
   },
   "source": [
    "---\n",
    "\n",
    "<span style=\"color:red\"><b>TASK 4</b> - Improved Training:</span>\n",
    "\n",
    "---\n",
    "\n",
    "Improve the above training loop with the following steps:\n",
    "1. replace the very basic SGD optimizer with the momentum-based [`torch.optim.Adam`](https://pytorch.org/docs/stable/generated/torch.optim.Adam.html) optimizer. Compare how the learning curves change after this step. **As ADAM is more sensitive to the learning rate, set it to `0.001` after changing the optimizer!**\n",
    "2. add a [`torch.optim.lr_scheduler.LinearLR`](https://pytorch.org/docs/stable/generated/torch.optim.lr_scheduler.LinearLR.html) scheduler (_start: `1.0*lr`, end:`0.33*lr`, over 10 epochs_).  Compare how the learning curves change after this step.\n",
    "3. add an **early stopping** functionality, that stops training when the validation loss has not improved for `patience` epochs and restores the model parameters to the ones achieving the best loss. **Use a patience of `5` to retrain the network.**\n",
    "\n",
    "**Disclaimer:** *We will not check whether you actually compare the loss curves before and after adding a specific step. But we may ask about their impact in the final exam.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "id": "pwOaMCDSTOpS"
   },
   "outputs": [],
   "source": [
    "def epoch(model, loader_train: DataLoader, optimizer: pt.optim.Optimizer, \n",
    "          loss_fn: Callable[[pt.Tensor, pt.Tensor], pt.Tensor], device):\n",
    "    model.train()\n",
    "    losses = []\n",
    "\n",
    "    with pt.enable_grad():\n",
    "        for X_batch, y_batch in loader_train:\n",
    "            X_batch = X_batch.reshape(X_batch.shape[0], -1).to(device)\n",
    "            y_batch = y_batch.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            y_pred = model(X_batch)\n",
    "            loss = loss_fn(y_pred, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            losses.append(loss.detach().cpu().numpy())\n",
    "    \n",
    "    return np.mean(losses)\n",
    "\n",
    "\n",
    "def evaluate(model, loader_valid: DataLoader, device, \n",
    "             loss_fn: Optional[Callable[[pt.Tensor, pt.Tensor], pt.Tensor]] = None):\n",
    "    model.eval()\n",
    "    labels = []\n",
    "    predictions = []\n",
    "    losses = []\n",
    "\n",
    "    with pt.no_grad():\n",
    "        for X_batch, y_batch in loader_valid:\n",
    "            X_batch = X_batch.reshape(X_batch.shape[0], -1).to(device)\n",
    "            y_batch = y_batch.to(device)\n",
    "\n",
    "            y_pred = model(X_batch)\n",
    "            labels.extend(y_batch.detach().cpu().numpy())\n",
    "            predictions.extend(y_pred.detach().cpu().numpy())\n",
    "\n",
    "            if loss_fn is not None:\n",
    "                losses.append(loss_fn(y_pred, y_batch).detach().cpu().numpy())\n",
    "\n",
    "    f1 = f1_score(\n",
    "        np.array(labels),\n",
    "        np.array(predictions).argmax(axis=1),\n",
    "        average='macro'\n",
    "    )\n",
    "\n",
    "    if loss_fn is None:\n",
    "        return {'f1': f1}\n",
    "    else:\n",
    "        return {'loss': np.mean(losses), 'f1': f1}\n",
    "\n",
    "\n",
    "def fit(model, loader_train: DataLoader, loader_valid: DataLoader, \n",
    "        epochs: int, lr: float = 0.001, patience: int = 5, device: str = 'cpu'):\n",
    "    #修改了函数的默认值，我们现在不输入也有默认值可以使用了，默认值为0.001学习率\n",
    "    optimizer = pt.optim.Adam(model.parameters(), lr=lr)\n",
    "    #这里是进行的学习率变化，参数分别是：优化器，开始系数，停止系数，\n",
    "    #总共多少个epoch后完成，其中我们的学习率会通过（系数 * 学习率）得到\n",
    "    scheduler = pt.optim.lr_scheduler.LinearLR(optimizer, start_factor=1.0, end_factor=0.33, total_iters=10)\n",
    "    loss_fn = pt.nn.CrossEntropyLoss()\n",
    "    history = []\n",
    "\n",
    "    best_loss = float('inf')\n",
    "    best_model = {k: v.clone() for k, v in model.state_dict().items()}\n",
    "    patience_counter = 0\n",
    "\n",
    "    for i in range(epochs):\n",
    "        loss_train = epoch(model, loader_train, optimizer, loss_fn, device)\n",
    "        metrics = evaluate(model, loader_valid, device, loss_fn)\n",
    "\n",
    "        history.append({\n",
    "            'epoch': i,\n",
    "            'loss_train': loss_train,\n",
    "            'loss_valid': metrics['loss'],\n",
    "            'f1_valid': metrics['f1']\n",
    "        })\n",
    "        #这里判断我们的loss是否更优，如果是储存loss并且回储存我们当前的模型\n",
    "        if metrics['loss'] < best_loss:\n",
    "            best_loss = metrics['loss']\n",
    "            #这里直接把我们的模型的参数保存下来了，加载时使用load_state_dict(模型)即可,\n",
    "            #state_dict方法是每一个实现了\n",
    "            #PyTorch 中每个 nn.Module（包括你自定义的模型类）自带的方法\n",
    "            #deepcopy是复制我们的对象的所有的内容，层级结构以及参数，用在（状态保存、结构嵌套的内容）\n",
    "            #copy只会复制最外层的，并且copy内部实际上是指针结构，\n",
    "            #所以说数据结构等用deepcopy，copy一般用在（简单结构，单层数据）\n",
    "            best_model = copy.deepcopy(model.state_dict())\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= patience:\n",
    "                break\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "    model.load_state_dict(best_model)\n",
    "    return pd.DataFrame(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 以上三点的提升：\n",
    "1.使用了另外的优化器，我们的模型会收敛的更快，每一个参数都会自动适配学习率，对学习率不敏感，一般设置为0.001\n",
    "\\\n",
    "2.添加了学习率调度器，是我们的学习率慢慢变化，不至于容易错过最佳点\n",
    "\n",
    "3.添加了了提前停止功能，我们的模型在达到阈值次数没有明显的变化后，便会停止然后输出有着良好表现的模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9r-hDPkRUY0R"
   },
   "source": [
    "---\n",
    "\n",
    "*End of Task 4. Copy your final code to **Homework 2 - Code** on **NextIlearn***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UKm2rIvKUP2C"
   },
   "source": [
    "### Section 4: Other useful and frequently used functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fp4BHXYqUWBH"
   },
   "source": [
    "Save and load the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rBmnCPTdaAlV"
   },
   "source": [
    "**Option 1:** `torch.save(...)` / `torch.load(...)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QQIhSX16UXpR"
   },
   "outputs": [],
   "source": [
    "pt.save(model, 'model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HrmRkkvbVYqj",
    "outputId": "dd43ea93-c413-4390-f3cc-a53d2aa2076d"
   },
   "outputs": [],
   "source": [
    "# this saves a zipfile!\n",
    "!unzip model.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sexXOBTKUZH_",
    "outputId": "6cb76ada-270e-46ec-a15f-a3fc0f7a5c5d"
   },
   "outputs": [],
   "source": [
    "model = pt.load('model.pt', weights_only=False) # \"weights_only = True\" only loads PyTorch Tensors in the model file!\n",
    "summary(model, input_size=(784,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cr88yK-8Z5GY"
   },
   "source": [
    "**Option 2:** save/load state_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FsXhrkFhZ9NY"
   },
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "44MB9qujUPys"
   },
   "outputs": [],
   "source": [
    "with open('model_state_dict.pkl', 'wb') as f:\n",
    "  pickle.dump(model.state_dict(), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_CuVaeSJZgW0",
    "outputId": "e6e1e1d6-0055-4ec0-a53c-2ab7d04af24a"
   },
   "outputs": [],
   "source": [
    "with open('model_state_dict.pkl', 'rb') as f:\n",
    "  state_dict = pickle.load(f)\n",
    "model.load_state_dict(state_dict)\n",
    "summary(model, input_size=(784,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w003CKN5R7vY"
   },
   "source": [
    "---\n",
    "\n",
    "<span style=\"color:red\"><b>TASK 5</b> - Regression MLP</span>\n",
    "\n",
    "---\n",
    "\n",
    "We have created a classification model on Fashion MNIST with PyTorch. In addition, we can of course use similar PyTorch models to solve regression tasks. **How can we do that?** Which part should we change to make it work on regression tasks? That would be our last task in this lab. Based on your knowledge from the second lecture, you may be able to figure out which part you need to change.\n",
    "\n",
    "Create a regression model by adapting the PyTorch model we used above and train it on the [california housing dataset](https://nextilearn.dsv.su.se/mod/resource/view.php?id=25386 ).\n",
    "You may need to change **a loss function** and input / output layers as we no longer deal with images and classification. Feel free to use scikit-learn but we still recommend you to practice preprocessing with NumPy for your skills.\n",
    "\n",
    "**Upload the resulting predictions to NextIlearn. Your model should achieve an MSE < XXX to pass.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qforG1NGbEuq"
   },
   "source": [
    "1. Get training and test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YpmUlavla3Py",
    "outputId": "a039de5d-514b-4452-baf0-efcfa18b4759"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data_test.csv', 'data_train.csv', 'description.md', 'labels_train.csv']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1.1 download https://www.google.com/url?q=https%3A%2F%2Fnextilearn.dsv.su.se%2Fmod%2Fresource%2Fview.php%3Fid%3D25386 to data.zip\n",
    "\n",
    "# 1.2 unzip data.zip\n",
    "#!unzip data.zip\n",
    "\n",
    "# 1.3 check files:\n",
    "os.listdir('data/data/task5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VYYglS3ybCM8"
   },
   "source": [
    "2. Create Data Pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "NQ_Rj925R7vY"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 2.1 load training data:\n",
    "data_train = pd.read_csv('data/data/task5/data_train.csv', index_col=0)\n",
    "labels_train = pd.read_csv('data/data/task5/labels_train.csv', index_col=0)\n",
    "\n",
    "# 2.2 load test data (no labels):\n",
    "data_test = pd.read_csv('data/data/task5/data_test.csv', index_col=0)\n",
    "\n",
    "#...\n",
    "X = data_train.values\n",
    "y = labels_train.values\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X_test = scaler.transform(data_test.values)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_scaled, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XaRz2hDYbYJ6"
   },
   "source": [
    "3. Create Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "nl0-sMfCR7vZ"
   },
   "outputs": [],
   "source": [
    "#...\n",
    "import torch \n",
    "import torch.nn as nn \n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "X_train_tensor = torch.tensor(X_train, dtype= torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype= torch.float32)\n",
    "X_val_tensor = torch.tensor(X_val, dtype= torch.float32)\n",
    "y_val_tensor = torch.tensor(y_val, dtype= torch.float32)\n",
    "\n",
    "X_test_tensor = torch.tensor(X_test, dtype= torch.float32)\n",
    "\n",
    "train_ds = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_ds, batch_size=32, shuffle=True)\n",
    "\n",
    "class MLPprocessor(nn.Module):\n",
    "    def __init__(self, inputdim):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(inputdim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "model = MLPprocessor(inputdim= X.shape[1])       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TzSyLqesbkYc"
   },
   "source": [
    "4. Train model on `data_train` and `labels_train`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "_dqM_Yzyb1ho"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Validation MSE: 0.5046\n",
      "Epoch 10, Validation MSE: 0.3093\n",
      "Epoch 20, Validation MSE: 0.2901\n",
      "Epoch 30, Validation MSE: 0.2899\n",
      "Epoch 40, Validation MSE: 0.2868\n",
      "Epoch 50, Validation MSE: 0.3068\n",
      "Epoch 60, Validation MSE: 0.2851\n",
      "Epoch 70, Validation MSE: 0.3024\n",
      "Epoch 80, Validation MSE: 0.3084\n",
      "Epoch 90, Validation MSE: 0.2743\n"
     ]
    }
   ],
   "source": [
    "#...\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range(100):\n",
    "    model.train()\n",
    "    for xb, yb in train_loader:\n",
    "        pred = model(xb).squeeze()\n",
    "        loss = criterion(pred, yb.squeeze())\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_pred = model(X_val_tensor).squeeze()\n",
    "            val_loss = criterion(val_pred, y_val_tensor.squeeze())\n",
    "            print(f\"Epoch {epoch}, Validation MSE: {val_loss.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-ipIi84zb5ZR"
   },
   "source": [
    "5. Predict `data_test` and save predictions to `submission.csv`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "V_gqdJvucm2l"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Unnamed: 0', 'predictions']\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    predictions = model(X_test_tensor)\n",
    "\n",
    "pd.DataFrame(predictions.detach().cpu().numpy(), columns=['predictions']).to_csv('submission.csv', index=True, encoding='utf-8')\n",
    "\n",
    "df_check = pd.read_csv('submission.csv')\n",
    "print(df_check.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aB-ezFJER7vZ"
   },
   "source": [
    "---\n",
    "\n",
    "*End of Task 5. Upload your final predictions (the file* `submission.csv` *) to **Homework 2 - Code** on **NextIlearn***"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
